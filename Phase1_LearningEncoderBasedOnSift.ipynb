{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Flatten, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import random\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 16, 16\n",
    "\n",
    "nb_epoch = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/niaki/Code/ImageNet/tiny-imagenet-200'\n",
    "\n",
    "train_data_dir      = base_dir + '/tiny_train16'\n",
    "validation_data_dir = base_dir + '/tiny_validation16'\n",
    "test_data_dir       = base_dir + '/tiny_test16'\n",
    "\n",
    "train_descrs_dir      = base_dir + '/tiny_sifts/tiny_train16'\n",
    "validation_descrs_dir = base_dir + '/tiny_sifts/tiny_validation16'\n",
    "test_descrs_dir       = base_dir + '/tiny_sifts/tiny_test16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(data_dir):\n",
    "    files = listdir(data_dir + '/class0')\n",
    "    files.sort()\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for file in files:\n",
    "        image = imageio.imread(data_dir + '/class0/' + file)\n",
    "    #     image = np.expand_dims(image, axis=0)\n",
    "        images.append(image)\n",
    "\n",
    "    images = np.array(images)\n",
    "    images = images.astype(np.float64) / 255\n",
    "    print(images.shape)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157086, 16, 16, 3)\n",
      "(3932, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = loading_data(train_data_dir)\n",
    "x_validation = loading_data(validation_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_descrs(descrs_dir):\n",
    "    files = listdir(descrs_dir + '/class0')\n",
    "    files.sort()\n",
    "\n",
    "    descrs = []\n",
    "\n",
    "    for file in files:\n",
    "        descr = np.load(descrs_dir + '/class0/' + file)\n",
    "        descrs.append(descr)\n",
    "\n",
    "    descrs = np.array(descrs)\n",
    "    descrs = descrs.astype(np.float64) / 255\n",
    "    print(descrs.shape)\n",
    "    return descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157086, 128)\n",
      "(3932, 128)\n"
     ]
    }
   ],
   "source": [
    "y_train = loading_descrs(train_descrs_dir)\n",
    "y_validation = loading_descrs(validation_descrs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be deleted from here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_y_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,  39., 137., 106.,  43.,\n",
       "         47.,  71., 119.,  85.,  53., 137., 102.,  23.,  22.,  34., 107.,\n",
       "        137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,  32.,  89.,  52.,  67.,  91.,\n",
       "        113., 137., 137.,  47., 116.,  50.,  31.,  41.,  54., 137., 137.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_y.reshape((1,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss_check(y_true, y_pred):\n",
    "    return np.sum(y_true - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLoss(y_true, y_pred):\n",
    "    return K.sum(y_true - y_pred)\n",
    "#     return K.sum(K.log(y_true) - K.log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customLoss(temp_y.reshape((1,128)), temp_y_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2590.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customLoss_check(temp_y.reshape((1,128)), temp_y_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_6:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customLoss(3, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument must be a dense tensor: (array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,  39., 137., 106.,  43.,\n         47.,  71., 119.,  85.,  53., 137., 102.,  23.,  22.,  34., 107.,\n        137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,  32.,  89.,  52.,  67.,  91.,\n        113., 137., 137.,  47., 116.,  50.,  31.,  41.,  54., 137., 137.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n      dtype=float32)) - got shape [2, 1, 128], but wanted [2].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-1f723e8f3f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_y_prime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msum\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \"\"\"\n\u001b[0;32m-> 1288\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_sum_v1\u001b[0;34m(input_tensor, axis, keepdims, name, reduction_indices, keep_dims)\u001b[0m\n\u001b[1;32m   1408\u001b[0m   keepdims = deprecation.deprecated_argument_lookup(\"keepdims\", keepdims,\n\u001b[1;32m   1409\u001b[0m                                                     \"keep_dims\", keep_dims)\n\u001b[0;32m-> 1410\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mreduce_sum\u001b[0;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[1;32m   1455\u001b[0m       \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m       gen_math_ops._sum(\n\u001b[0;32m-> 1457\u001b[0;31m           \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ReductionDims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1458\u001b[0m           name=name))\n\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_ReductionDims\u001b[0;34m(x, axis, reduction_indices)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0;31m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mrank\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m   \"\"\"\n\u001b[0;32m--> 486\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mrank_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mrank_internal\u001b[0;34m(input, name, optimize)\u001b[0m\n\u001b[1;32m    504\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m       \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                          as_ref=False):\n\u001b[1;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[1;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 246\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    283\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    285\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    473\u001b[0m                          \u001b[0;34m\"\"\" - got shape %s, but wanted %s.\"\"\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                          (values, list(nparray.shape),\n\u001b[0;32m--> 475\u001b[0;31m                           _GetDenseDimensions(values)))\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;31m# python/numpy default float type is float64. We prefer float32 instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument must be a dense tensor: (array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,  39., 137., 106.,  43.,\n         47.,  71., 119.,  85.,  53., 137., 102.,  23.,  22.,  34., 107.,\n        137.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,  32.,  89.,  52.,  67.,  91.,\n        113., 137., 137.,  47., 116.,  50.,  31.,  41.,  54., 137., 137.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.]], dtype=float32), array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n      dtype=float32)) - got shape [2, 1, 128], but wanted [2]."
     ]
    }
   ],
   "source": [
    "K.sum((temp_y.reshape((1,128)), temp_y_prime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3], dtype=np.float32).reshape((1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([100,20,300], dtype=np.float32).reshape((1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = np.zeros((2,3), dtype=np.float32)\n",
    "ab[0] = a\n",
    "ab[1] = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum_9:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.sum(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'keras.backend' from '/scratch/tensorflow/lib/python3.6/site-packages/keras/backend/__init__.py'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... until here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSLE_plus_plus(y_true, y_pred):\n",
    "    if not K.is_tensor(y_pred):\n",
    "        y_pred = K.constant(y_pred)\n",
    "    y_true = K.cast(y_true, y_pred.dtype)\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    custom_loss_log = K.log(K.clip(y_true + y_pred, K.epsilon(), None) + 1.)\n",
    "    custom_loss_denominator = (y_true * y_pred + 0.005) * 256  # parameters to be further adjusted\n",
    "    return K.mean(K.square(first_log - second_log) + custom_loss_log / custom_loss_denominator, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1118 16:30:13.426448 139665879115584 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1118 16:30:13.446276 139665879115584 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1118 16:30:13.451584 139665879115584 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1118 16:30:13.467727 139665879115584 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W1118 16:30:13.500892 139665879115584 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1118 16:30:13.510314 139665879115584 deprecation_wrapper.py:119] From /scratch/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16, 16, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "=================================================================\n",
      "Total params: 35,904\n",
      "Trainable params: 35,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_width, img_height, 3)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = Flatten(data_format=\"channels_last\")(x)\n",
    "encoded = Dense(128, activation=\"sigmoid\")(x)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "encoder.compile(optimizer='adadelta', metrics=['accuracy'], loss=MSLE_plus_plus)\n",
    "#next up: encoder.compile(optimizer='sgd', metrics=['categorical_accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_generator(x_train, y_train, batch_size):\n",
    "    while True:\n",
    "        batch_list_x = []\n",
    "        batch_list_y = []\n",
    "        \n",
    "        for i in range(x_train.shape[0]):\n",
    "            batch_list_x.append(x_train[i])\n",
    "            batch_list_y.append(y_train[i])\n",
    "            if len(batch_list_x) == batch_size:\n",
    "                yield (np.array(batch_list_x),np.array(batch_list_y))\n",
    "                batch_list_x = []\n",
    "                batch_list_y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "157086/157086 [==============================] - 813s 5ms/step - loss: 0.0065 - acc: 0.1210 - val_loss: 0.0067 - val_acc: 0.1499\n",
      "Epoch 2/70\n",
      "157086/157086 [==============================] - 802s 5ms/step - loss: 0.0065 - acc: 0.1203 - val_loss: 0.0064 - val_acc: 0.1342\n",
      "Epoch 3/70\n",
      "157086/157086 [==============================] - 796s 5ms/step - loss: 0.0065 - acc: 0.1183 - val_loss: 0.0065 - val_acc: 0.1161\n",
      "Epoch 4/70\n",
      "157086/157086 [==============================] - 796s 5ms/step - loss: 0.0065 - acc: 0.1172 - val_loss: 0.0065 - val_acc: 0.1066\n",
      "Epoch 5/70\n",
      "157086/157086 [==============================] - 787s 5ms/step - loss: 0.0065 - acc: 0.1175 - val_loss: 0.0065 - val_acc: 0.1322\n",
      "Epoch 6/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1181 - val_loss: 0.0080 - val_acc: 0.0935\n",
      "Epoch 7/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1190 - val_loss: 0.0065 - val_acc: 0.1202\n",
      "Epoch 8/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1200 - val_loss: 0.0064 - val_acc: 0.1207\n",
      "Epoch 9/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1207 - val_loss: 0.0065 - val_acc: 0.1274\n",
      "Epoch 10/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1212 - val_loss: 0.0064 - val_acc: 0.1795\n",
      "Epoch 11/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1216 - val_loss: 0.0065 - val_acc: 0.1353\n",
      "Epoch 12/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1220 - val_loss: 0.0065 - val_acc: 0.1828\n",
      "Epoch 13/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1216 - val_loss: 0.0064 - val_acc: 0.1193\n",
      "Epoch 14/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1217 - val_loss: 0.0065 - val_acc: 0.1281\n",
      "Epoch 15/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1217 - val_loss: 0.0064 - val_acc: 0.1283\n",
      "Epoch 16/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1216 - val_loss: 0.0065 - val_acc: 0.1042\n",
      "Epoch 17/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1212 - val_loss: 0.0066 - val_acc: 0.1016\n",
      "Epoch 18/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1214 - val_loss: 0.0071 - val_acc: 0.1205\n",
      "Epoch 19/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1214 - val_loss: 0.0065 - val_acc: 0.0991\n",
      "Epoch 20/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1210 - val_loss: 0.0065 - val_acc: 0.1191\n",
      "Epoch 21/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1208 - val_loss: 0.0064 - val_acc: 0.1550\n",
      "Epoch 22/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1210 - val_loss: 0.0070 - val_acc: 0.1126\n",
      "Epoch 23/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1208 - val_loss: 0.0065 - val_acc: 0.1447\n",
      "Epoch 24/70\n",
      "157086/157086 [==============================] - 787s 5ms/step - loss: 0.0065 - acc: 0.1204 - val_loss: 0.0065 - val_acc: 0.1329\n",
      "Epoch 25/70\n",
      "157086/157086 [==============================] - 787s 5ms/step - loss: 0.0065 - acc: 0.1207 - val_loss: 0.0065 - val_acc: 0.1569\n",
      "Epoch 26/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1207 - val_loss: 0.0064 - val_acc: 0.1496\n",
      "Epoch 27/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1210 - val_loss: 0.0064 - val_acc: 0.0893\n",
      "Epoch 28/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1209 - val_loss: 0.0065 - val_acc: 0.1183\n",
      "Epoch 29/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1209 - val_loss: 0.0065 - val_acc: 0.1064\n",
      "Epoch 30/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1212 - val_loss: 0.0064 - val_acc: 0.1440\n",
      "Epoch 31/70\n",
      "157086/157086 [==============================] - 787s 5ms/step - loss: 0.0065 - acc: 0.1208 - val_loss: 0.0066 - val_acc: 0.0948\n",
      "Epoch 32/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1208 - val_loss: 0.0065 - val_acc: 0.1142\n",
      "Epoch 33/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1210 - val_loss: 0.0065 - val_acc: 0.1173\n",
      "Epoch 34/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1209 - val_loss: 0.0065 - val_acc: 0.1383\n",
      "Epoch 35/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1209 - val_loss: 0.0067 - val_acc: 0.1159\n",
      "Epoch 36/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1209 - val_loss: 0.0066 - val_acc: 0.1152\n",
      "Epoch 37/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1207 - val_loss: 0.0069 - val_acc: 0.1443\n",
      "Epoch 38/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1205 - val_loss: 0.0064 - val_acc: 0.1078\n",
      "Epoch 39/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1202 - val_loss: 0.0066 - val_acc: 0.1055\n",
      "Epoch 40/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1205 - val_loss: 0.0065 - val_acc: 0.1355\n",
      "Epoch 41/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1204 - val_loss: 0.0065 - val_acc: 0.1335\n",
      "Epoch 42/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1208 - val_loss: 0.0071 - val_acc: 0.1383\n",
      "Epoch 43/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1207 - val_loss: 0.0065 - val_acc: 0.1445\n",
      "Epoch 44/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1205 - val_loss: 0.0064 - val_acc: 0.1161\n",
      "Epoch 45/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1206 - val_loss: 0.0066 - val_acc: 0.0995\n",
      "Epoch 46/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1206 - val_loss: 0.0066 - val_acc: 0.1394\n",
      "Epoch 47/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1209 - val_loss: 0.0064 - val_acc: 0.1489\n",
      "Epoch 48/70\n",
      "157086/157086 [==============================] - 788s 5ms/step - loss: 0.0065 - acc: 0.1211 - val_loss: 0.0066 - val_acc: 0.1161\n",
      "Epoch 49/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1212 - val_loss: 0.0065 - val_acc: 0.1171\n",
      "Epoch 50/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1213 - val_loss: 0.0066 - val_acc: 0.1301\n",
      "Epoch 51/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1213 - val_loss: 0.0067 - val_acc: 0.1414\n",
      "Epoch 52/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1214 - val_loss: 0.0065 - val_acc: 0.1406\n",
      "Epoch 53/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1216 - val_loss: 0.0065 - val_acc: 0.1033\n",
      "Epoch 54/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1211 - val_loss: 0.0064 - val_acc: 0.1337\n",
      "Epoch 55/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1211 - val_loss: 0.0065 - val_acc: 0.1164\n",
      "Epoch 56/70\n",
      "157086/157086 [==============================] - 784s 5ms/step - loss: 0.0065 - acc: 0.1210 - val_loss: 0.0064 - val_acc: 0.1319\n",
      "Epoch 57/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1206 - val_loss: 0.0064 - val_acc: 0.1741\n",
      "Epoch 58/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1205 - val_loss: 0.0065 - val_acc: 0.1182\n",
      "Epoch 59/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1203 - val_loss: 0.0064 - val_acc: 0.1080\n",
      "Epoch 60/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1201 - val_loss: 0.0064 - val_acc: 0.1280\n",
      "Epoch 61/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1194 - val_loss: 0.0067 - val_acc: 0.0982\n",
      "Epoch 62/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1192 - val_loss: 0.0064 - val_acc: 0.1265\n",
      "Epoch 63/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1190 - val_loss: 0.0064 - val_acc: 0.1062\n",
      "Epoch 64/70\n",
      "157086/157086 [==============================] - 787s 5ms/step - loss: 0.0065 - acc: 0.1188 - val_loss: 0.0064 - val_acc: 0.1348\n",
      "Epoch 65/70\n",
      "157086/157086 [==============================] - 787s 5ms/step - loss: 0.0065 - acc: 0.1188 - val_loss: 0.0065 - val_acc: 0.1194\n",
      "Epoch 66/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1185 - val_loss: 0.0066 - val_acc: 0.1451\n",
      "Epoch 67/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1183 - val_loss: 0.0064 - val_acc: 0.1310\n",
      "Epoch 68/70\n",
      "157086/157086 [==============================] - 785s 5ms/step - loss: 0.0065 - acc: 0.1190 - val_loss: 0.0063 - val_acc: 0.1002\n",
      "Epoch 69/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1202 - val_loss: 0.0067 - val_acc: 0.0955\n",
      "Epoch 70/70\n",
      "157086/157086 [==============================] - 786s 5ms/step - loss: 0.0065 - acc: 0.1202 - val_loss: 0.0064 - val_acc: 0.1135\n"
     ]
    }
   ],
   "source": [
    "model_version = '1.0.0.6_encoder_lastsigmoid_mslepp_adadelta_metricsaccuracy_trainedmore'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights' + model_version)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "encoder.fit_generator(fixed_generator(x_train, y_train, 32),\n",
    "                steps_per_epoch=157086,\n",
    "                epochs=70,\n",
    "                validation_data=fixed_generator(x_validation, y_validation, 32),\n",
    "                validation_steps=3932,\n",
    "                callbacks=[checkpointer]\n",
    "                )\n",
    "encoder.save(base_dir + '/ae' + model_version + '.h5')\n",
    "\n",
    "# import keras.losses\n",
    "# keras.losses.MSLE_plus_plus = MSLE_plus_plus\n",
    "# encoder = load_model(base_dir + '/ae' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_test16/class0/patch000026.png\").reshape(1,16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y_prime = encoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_train16/class0/patch000012.png\").reshape(1,16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y = np.load(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_sifts/tiny_train16/class0/patch000012.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6393183138370047 \n",
      "\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "   91.000000    1.000000\n",
      "   18.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    1.000000    0.000000\n",
      "    7.000000    1.000000\n",
      "   56.000000    0.000000\n",
      "  157.000000    0.000000\n",
      "  157.000000    1.000000\n",
      "  103.000000    1.000000\n",
      "   21.000000    0.000000\n",
      "    2.000000    1.000000\n",
      "    3.000000    0.000000\n",
      "   16.000000    1.000000\n",
      "   96.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "  110.000000    1.000000\n",
      "   14.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    3.000000    0.000000\n",
      "    9.000000    0.984089\n",
      "   33.000000    0.000000\n",
      "  157.000000    0.000000\n",
      "  157.000000    1.000000\n",
      "  125.000000    1.000000\n",
      "   15.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    9.000000    0.000000\n",
      "   25.000000    1.000000\n",
      "   48.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(temp_y, temp_y_prime[0])[1,0], \"\\n\")\n",
    "for i in range(temp_y_prime.shape[1]):\n",
    "    print('{:>12f}{:>12f}'.format(temp_y[i], temp_y_prime[0, i]))      \n",
    "#     print(temp_y_prime[0, i], temp_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 3.427e-06, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(temp, decimals=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
