{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Flatten, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import random\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 31, 31\n",
    "\n",
    "nb_epoch = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/scratch/image_datasets/1_for_learned_sift/ridiculously_small'\n",
    "\n",
    "train_data_dir      = base_dir + '/patches/train'\n",
    "validation_data_dir = base_dir + '/patches/validation'\n",
    "# test_data_dir       = base_dir + '/patches/test'\n",
    "\n",
    "train_descrs_dir      = base_dir + '/descriptors_angles/train'\n",
    "validation_descrs_dir = base_dir + '/descriptors_angles/validation'\n",
    "# test_descrs_dir       = base_dir + '/descriptors_angles/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(dir_patches, dir_descrs):\n",
    "    files_patches = listdir(dir_patches + '/class0')\n",
    "    files_patches.sort()\n",
    "    \n",
    "    files_descrs = listdir(dir_descrs + '/class0')\n",
    "    files_descrs.sort()\n",
    "    \n",
    "    assert len(files_patches) == len(files_descrs), \"The number of patches doesn't match the number of descriptors.\"\n",
    "\n",
    "    patches = []\n",
    "    descrs = []\n",
    "\n",
    "    \n",
    "    for file_patch, file_descr in zip(files_patches, files_descrs):\n",
    "        patch = imageio.imread(dir_patches + '/class0/' + file_patch)\n",
    "#         print(patch.shape)\n",
    "        if patch.shape[0] == 31:\n",
    "            patches.append(patch)\n",
    "            descr = np.load(dir_descrs + '/class0/' + file_descr)\n",
    "            descrs.append(descr)\n",
    "#         elif image.shape[0] == 19:\n",
    "#             temp_count19 += 1\n",
    "        \n",
    "        \n",
    "\n",
    "    patches = np.array(patches)\n",
    "    patches = patches.astype(np.float64) / 255\n",
    "    \n",
    "    descrs = np.array(descrs)\n",
    "    descrs = (descrs.astype(np.float64) / 255)\n",
    "    print(\"patches\", patches.shape, \"  descrs\", descrs.shape)\n",
    "    \n",
    "    return patches, descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches (35, 31, 31)   descrs (35, 129)\n",
      "patches (25, 31, 31)   descrs (25, 129)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = loading_data(train_data_dir, train_descrs_dir)\n",
    "x_validation, y_validation = loading_data(validation_data_dir, validation_descrs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[2], x_train.shape[2], 1))\n",
    "x_validation = x_validation.reshape((x_validation.shape[0], x_validation.shape[2], x_validation.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 31, 31, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSLE_plus_plus(y_true, y_pred):\n",
    "    if not K.is_tensor(y_pred):\n",
    "        y_pred = K.constant(y_pred)\n",
    "    y_true = K.cast(y_true, y_pred.dtype)\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    custom_loss_log = K.log(K.clip(y_true + y_pred, K.epsilon(), None) + 1.)\n",
    "    custom_loss_denominator = (y_true * y_pred + 0.005) * 256  # parameters to be further adjusted\n",
    "    return K.mean(K.square(first_log - second_log) + custom_loss_log / custom_loss_denominator, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18039216, -0.16862745, -0.16862745, -0.18823529, -0.14509804,\n",
       "       -0.17254902, -0.10588235, -0.01960784, -0.16862745, -0.14509804,\n",
       "       -0.09803922, -0.17647059, -0.14509804,  0.00392157,  0.0745098 ,\n",
       "       -0.06666667, -0.19215686, -0.19607843, -0.16862745, -0.14509804,\n",
       "        0.16470588,  0.29019608, -0.10980392, -0.15294118, -0.17254902,\n",
       "       -0.19607843, -0.19607843, -0.19607843, -0.16470588, -0.10588235,\n",
       "       -0.11764706, -0.02352941, -0.18823529, -0.02745098,  0.29019608,\n",
       "       -0.14117647, -0.19607843, -0.2       , -0.19607843, -0.18039216,\n",
       "       -0.13333333, -0.0745098 ,  0.29019608,  0.01176471, -0.17254902,\n",
       "       -0.18823529, -0.19607843, -0.18431373,  0.03529412, -0.1254902 ,\n",
       "        0.05098039, -0.08235294, -0.01176471, -0.10588235,  0.03529412,\n",
       "        0.08627451, -0.18823529, -0.2       , -0.2       , -0.2       ,\n",
       "       -0.16862745,  0.10196078,  0.29019608, -0.01176471, -0.2       ,\n",
       "       -0.10196078,  0.25098039, -0.09019608, -0.2       , -0.2       ,\n",
       "       -0.2       , -0.2       ,  0.0627451 ,  0.02745098,  0.18039216,\n",
       "       -0.00784314, -0.2       , -0.2       , -0.2       , -0.19215686,\n",
       "        0.29019608,  0.29019608, -0.05490196, -0.2       , -0.2       ,\n",
       "       -0.2       , -0.14901961, -0.00392157, -0.13333333,  0.14509804,\n",
       "       -0.03137255, -0.18431373, -0.11764706, -0.02352941,  0.02352941,\n",
       "       -0.12156863, -0.2       , -0.19215686, -0.03529412, -0.1254902 ,\n",
       "       -0.18431373, -0.2       , -0.2       , -0.2       , -0.16470588,\n",
       "        0.01176471, -0.07843137, -0.09803922, -0.19607843, -0.2       ,\n",
       "       -0.2       , -0.2       , -0.01960784,  0.29019608,  0.05882353,\n",
       "       -0.19607843, -0.2       , -0.2       , -0.2       , -0.18431373,\n",
       "        0.10588235,  0.29019608, -0.01176471, -0.18431373, -0.15686275,\n",
       "       -0.18823529, -0.19607843, -0.09019608,  0.43529412])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 31, 31, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 29, 29, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 27, 27, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 25, 25, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 23, 23, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 21, 21, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 129)               51729     \n",
      "=================================================================\n",
      "Total params: 84,417\n",
      "Trainable params: 84,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_width, img_height, 1)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(input_img)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = Conv2D(16, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = MaxPooling2D((4, 4), padding=\"valid\")(x)\n",
    "x = Flatten(data_format=\"channels_last\")(x)\n",
    "encoded = Dense(129, activation=\"tanh\")(x)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "encoder.compile(optimizer='adadelta', loss=\"binary_crossentropy\")\n",
    "#next up: encoder.compile(optimizer='sgd', metrics=['categorical_accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_generator(x_train, y_train, batch_size):\n",
    "    while True:\n",
    "        batch_list_x = []\n",
    "        batch_list_y = []\n",
    "        \n",
    "        for i in range(x_train.shape[0]):\n",
    "            batch_list_x.append(x_train[i])\n",
    "            batch_list_y.append(y_train[i])\n",
    "            if len(batch_list_x) == batch_size:\n",
    "                yield (np.array(batch_list_x),np.array(batch_list_y))\n",
    "                batch_list_x = []\n",
    "                batch_list_y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "35/35 [==============================] - 1s 21ms/step - loss: -1.3535 - val_loss: -1.3650\n",
      "Epoch 2/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4398 - val_loss: -1.3630\n",
      "Epoch 3/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4485 - val_loss: -1.3724\n",
      "Epoch 4/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4449 - val_loss: -1.3427\n",
      "Epoch 5/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4492 - val_loss: -1.3746\n",
      "Epoch 6/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4478 - val_loss: -1.3698\n",
      "Epoch 7/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4541 - val_loss: -1.3836\n",
      "Epoch 8/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.4420 - val_loss: -1.3819\n",
      "Epoch 9/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4508 - val_loss: -1.3811\n",
      "Epoch 10/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.4482 - val_loss: -1.3793\n",
      "Epoch 11/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4552 - val_loss: -1.3762\n",
      "Epoch 12/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4466 - val_loss: -1.3752\n",
      "Epoch 13/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4532 - val_loss: -1.3873\n",
      "Epoch 14/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4571 - val_loss: -1.3836\n",
      "Epoch 15/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4614 - val_loss: -1.3722\n",
      "Epoch 16/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4583 - val_loss: -1.3673\n",
      "Epoch 17/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4693 - val_loss: -1.3813\n",
      "Epoch 18/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4650 - val_loss: -1.3834\n",
      "Epoch 19/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4666 - val_loss: -1.3772\n",
      "Epoch 20/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4616 - val_loss: -1.3709\n",
      "Epoch 21/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4683 - val_loss: -1.3720\n",
      "Epoch 22/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.4669 - val_loss: -1.3817\n",
      "Epoch 23/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4753 - val_loss: -1.3712\n",
      "Epoch 24/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.4709 - val_loss: -1.3804\n",
      "Epoch 25/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4813 - val_loss: -1.3822\n",
      "Epoch 26/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4731 - val_loss: -1.3738\n",
      "Epoch 27/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4795 - val_loss: -1.3804\n",
      "Epoch 28/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.4791 - val_loss: -1.4045\n",
      "Epoch 29/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5185 - val_loss: -1.3959\n",
      "Epoch 30/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5166 - val_loss: -1.4026\n",
      "Epoch 31/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5230 - val_loss: -1.4032\n",
      "Epoch 32/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5197 - val_loss: -1.4019\n",
      "Epoch 33/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5264 - val_loss: -1.4069\n",
      "Epoch 34/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5183 - val_loss: -1.3987\n",
      "Epoch 35/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5188 - val_loss: -1.4019\n",
      "Epoch 36/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5190 - val_loss: -1.3997\n",
      "Epoch 37/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5266 - val_loss: -1.4033\n",
      "Epoch 38/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5151 - val_loss: -1.4054\n",
      "Epoch 39/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5219 - val_loss: -1.4069\n",
      "Epoch 40/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5171 - val_loss: -1.4052\n",
      "Epoch 41/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5250 - val_loss: -1.4055\n",
      "Epoch 42/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5224 - val_loss: -1.3983\n",
      "Epoch 43/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5296 - val_loss: -1.4022\n",
      "Epoch 44/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5244 - val_loss: -1.4026\n",
      "Epoch 45/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5314 - val_loss: -1.4031\n",
      "Epoch 46/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5229 - val_loss: -1.3984\n",
      "Epoch 47/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5321 - val_loss: -1.3996\n",
      "Epoch 48/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5262 - val_loss: -1.3796\n",
      "Epoch 49/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5266 - val_loss: -1.3949\n",
      "Epoch 50/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5230 - val_loss: -1.4023\n",
      "Epoch 51/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5336 - val_loss: -1.4031\n",
      "Epoch 52/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5276 - val_loss: -1.4014\n",
      "Epoch 53/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5345 - val_loss: -1.4029\n",
      "Epoch 54/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5251 - val_loss: -1.4032\n",
      "Epoch 55/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5345 - val_loss: -1.3939\n",
      "Epoch 56/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5259 - val_loss: -1.3949\n",
      "Epoch 57/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5399 - val_loss: -1.3920\n",
      "Epoch 58/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5334 - val_loss: -1.3893\n",
      "Epoch 59/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5382 - val_loss: -1.3959\n",
      "Epoch 60/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5348 - val_loss: -1.3880\n",
      "Epoch 61/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5423 - val_loss: -1.3905\n",
      "Epoch 62/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5344 - val_loss: -1.3846\n",
      "Epoch 63/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5382 - val_loss: -1.3874\n",
      "Epoch 64/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5363 - val_loss: -1.3936\n",
      "Epoch 65/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5424 - val_loss: -1.3797\n",
      "Epoch 66/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5370 - val_loss: -1.3920\n",
      "Epoch 67/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5459 - val_loss: -1.3908\n",
      "Epoch 68/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5399 - val_loss: -1.3901\n",
      "Epoch 69/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5404 - val_loss: -1.3891\n",
      "Epoch 70/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5357 - val_loss: -1.3967\n",
      "Epoch 71/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5396 - val_loss: -1.3963\n",
      "Epoch 72/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5387 - val_loss: -1.3940\n",
      "Epoch 73/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5456 - val_loss: -1.3934\n",
      "Epoch 74/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5349 - val_loss: -1.3947\n",
      "Epoch 75/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5439 - val_loss: -1.3861\n",
      "Epoch 76/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5401 - val_loss: -1.3867\n",
      "Epoch 77/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5466 - val_loss: -1.3886\n",
      "Epoch 78/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5391 - val_loss: -1.3878\n",
      "Epoch 79/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5473 - val_loss: -1.3898\n",
      "Epoch 80/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5410 - val_loss: -1.3896\n",
      "Epoch 81/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5471 - val_loss: -1.3759\n",
      "Epoch 82/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5418 - val_loss: -1.3874\n",
      "Epoch 83/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5488 - val_loss: -1.3896\n",
      "Epoch 84/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5422 - val_loss: -1.3892\n",
      "Epoch 85/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5484 - val_loss: -1.3864\n",
      "Epoch 86/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5390 - val_loss: -1.3959\n",
      "Epoch 87/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5472 - val_loss: -1.3953\n",
      "Epoch 88/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5417 - val_loss: -1.3956\n",
      "Epoch 89/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5465 - val_loss: -1.3970\n",
      "Epoch 90/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5414 - val_loss: -1.3951\n",
      "Epoch 91/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5492 - val_loss: -1.3945\n",
      "Epoch 92/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5426 - val_loss: -1.3947\n",
      "Epoch 93/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5491 - val_loss: -1.3979\n",
      "Epoch 94/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5426 - val_loss: -1.3955\n",
      "Epoch 95/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5494 - val_loss: -1.3956\n",
      "Epoch 96/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5428 - val_loss: -1.3972\n",
      "Epoch 97/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5494 - val_loss: -1.3958\n",
      "Epoch 98/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5430 - val_loss: -1.3961\n",
      "Epoch 99/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5495 - val_loss: -1.3934\n",
      "Epoch 100/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5388 - val_loss: -1.3923\n",
      "Epoch 101/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5512 - val_loss: -1.3933\n",
      "Epoch 102/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5438 - val_loss: -1.3967\n",
      "Epoch 103/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5526 - val_loss: -1.3969\n",
      "Epoch 104/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5461 - val_loss: -1.3971\n",
      "Epoch 105/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5528 - val_loss: -1.3969\n",
      "Epoch 106/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5459 - val_loss: -1.3980\n",
      "Epoch 107/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5528 - val_loss: -1.3975\n",
      "Epoch 108/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5462 - val_loss: -1.3984\n",
      "Epoch 109/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5528 - val_loss: -1.3990\n",
      "Epoch 110/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5462 - val_loss: -1.3983\n",
      "Epoch 111/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5523 - val_loss: -1.3981\n",
      "Epoch 112/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5446 - val_loss: -1.3894\n",
      "Epoch 113/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5539 - val_loss: -1.3900\n",
      "Epoch 114/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5474 - val_loss: -1.3907\n",
      "Epoch 115/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5540 - val_loss: -1.3911\n",
      "Epoch 116/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5475 - val_loss: -1.3916\n",
      "Epoch 117/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5541 - val_loss: -1.3919\n",
      "Epoch 118/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5437 - val_loss: -1.3960\n",
      "Epoch 119/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5525 - val_loss: -1.3939\n",
      "Epoch 120/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5468 - val_loss: -1.3953\n",
      "Epoch 121/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5536 - val_loss: -1.3962\n",
      "Epoch 122/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5469 - val_loss: -1.3961\n",
      "Epoch 123/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5537 - val_loss: -1.3967\n",
      "Epoch 124/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5468 - val_loss: -1.3918\n",
      "Epoch 125/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5539 - val_loss: -1.3990\n",
      "Epoch 126/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5467 - val_loss: -1.3988\n",
      "Epoch 127/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5460 - val_loss: -1.4009\n",
      "Epoch 128/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5430 - val_loss: -1.4027\n",
      "Epoch 129/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5535 - val_loss: -1.3985\n",
      "Epoch 130/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5474 - val_loss: -1.3948\n",
      "Epoch 131/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5553 - val_loss: -1.3900\n",
      "Epoch 132/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5564 - val_loss: -1.3894\n",
      "Epoch 133/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5641 - val_loss: -1.3887\n",
      "Epoch 134/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5582 - val_loss: -1.3893\n",
      "Epoch 135/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5655 - val_loss: -1.3878\n",
      "Epoch 136/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5576 - val_loss: -1.3886\n",
      "Epoch 137/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5644 - val_loss: -1.3889\n",
      "Epoch 138/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5570 - val_loss: -1.3872\n",
      "Epoch 139/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5645 - val_loss: -1.3852\n",
      "Epoch 140/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5579 - val_loss: -1.3867\n",
      "Epoch 141/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5646 - val_loss: -1.3875\n",
      "Epoch 142/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5580 - val_loss: -1.3873\n",
      "Epoch 143/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5646 - val_loss: -1.3869\n",
      "Epoch 144/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5580 - val_loss: -1.3857\n",
      "Epoch 145/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5646 - val_loss: -1.3857\n",
      "Epoch 146/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5580 - val_loss: -1.3857\n",
      "Epoch 147/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5646 - val_loss: -1.3857\n",
      "Epoch 148/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5580 - val_loss: -1.3858\n",
      "Epoch 149/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5608 - val_loss: -1.3983\n",
      "Epoch 150/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5481 - val_loss: -1.4004\n",
      "Epoch 151/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5611 - val_loss: -1.3888\n",
      "Epoch 152/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5555 - val_loss: -1.3945\n",
      "Epoch 153/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5649 - val_loss: -1.3948\n",
      "Epoch 154/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5590 - val_loss: -1.3961\n",
      "Epoch 155/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5658 - val_loss: -1.3957\n",
      "Epoch 156/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5591 - val_loss: -1.3884\n",
      "Epoch 157/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5659 - val_loss: -1.3891\n",
      "Epoch 158/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5599 - val_loss: -1.3924\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5679 - val_loss: -1.3871\n",
      "Epoch 160/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5616 - val_loss: -1.3910\n",
      "Epoch 161/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5685 - val_loss: -1.3907\n",
      "Epoch 162/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5617 - val_loss: -1.3922\n",
      "Epoch 163/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5683 - val_loss: -1.3926\n",
      "Epoch 164/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5607 - val_loss: -1.3898\n",
      "Epoch 165/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5682 - val_loss: -1.3877\n",
      "Epoch 166/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5616 - val_loss: -1.3899\n",
      "Epoch 167/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5684 - val_loss: -1.3916\n",
      "Epoch 168/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5617 - val_loss: -1.3929\n",
      "Epoch 169/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5679 - val_loss: -1.3918\n",
      "Epoch 170/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5616 - val_loss: -1.3956\n",
      "Epoch 171/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5691 - val_loss: -1.3952\n",
      "Epoch 172/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5620 - val_loss: -1.3948\n",
      "Epoch 173/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5715 - val_loss: -1.3931\n",
      "Epoch 174/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3911\n",
      "Epoch 175/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5693 - val_loss: -1.3932\n",
      "Epoch 176/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5647 - val_loss: -1.3913\n",
      "Epoch 177/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5721 - val_loss: -1.3892\n",
      "Epoch 178/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5652 - val_loss: -1.3894\n",
      "Epoch 179/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5721 - val_loss: -1.3894\n",
      "Epoch 180/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5652 - val_loss: -1.3894\n",
      "Epoch 181/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5721 - val_loss: -1.3894\n",
      "Epoch 182/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5645 - val_loss: -1.3922\n",
      "Epoch 183/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3902\n",
      "Epoch 184/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3891\n",
      "Epoch 185/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3890\n",
      "Epoch 186/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3891\n",
      "Epoch 187/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3891\n",
      "Epoch 188/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3892\n",
      "Epoch 189/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3892\n",
      "Epoch 190/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3887\n",
      "Epoch 191/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3887\n",
      "Epoch 192/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3885\n",
      "Epoch 193/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3893\n",
      "Epoch 194/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3880\n",
      "Epoch 195/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3894\n",
      "Epoch 196/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3893\n",
      "Epoch 197/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3874\n",
      "Epoch 198/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3893\n",
      "Epoch 199/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3885\n",
      "Epoch 200/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3887\n",
      "Epoch 201/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3878\n",
      "Epoch 202/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3878\n",
      "Epoch 203/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3886\n",
      "Epoch 204/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3886\n",
      "Epoch 205/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3881\n",
      "Epoch 206/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3877\n",
      "Epoch 207/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3886\n",
      "Epoch 208/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3880\n",
      "Epoch 209/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3880\n",
      "Epoch 210/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3879\n",
      "Epoch 211/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3881\n",
      "Epoch 212/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3874\n",
      "Epoch 213/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 214/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3874\n",
      "Epoch 215/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3880\n",
      "Epoch 216/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3873\n",
      "Epoch 217/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3866\n",
      "Epoch 218/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3881\n",
      "Epoch 219/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3868\n",
      "Epoch 220/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3865\n",
      "Epoch 221/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3879\n",
      "Epoch 222/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3866\n",
      "Epoch 223/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3867\n",
      "Epoch 224/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3879\n",
      "Epoch 225/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3873\n",
      "Epoch 226/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3872\n",
      "Epoch 227/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3864\n",
      "Epoch 228/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3875\n",
      "Epoch 229/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3867\n",
      "Epoch 230/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 231/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3873\n",
      "Epoch 232/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3865\n",
      "Epoch 233/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3866\n",
      "Epoch 234/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3866\n",
      "Epoch 235/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3872\n",
      "Epoch 236/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3871\n",
      "Epoch 237/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3873\n",
      "Epoch 239/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3865\n",
      "Epoch 240/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3865\n",
      "Epoch 241/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3872\n",
      "Epoch 242/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3864\n",
      "Epoch 243/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3871\n",
      "Epoch 244/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3868\n",
      "Epoch 245/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3864\n",
      "Epoch 246/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 247/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 248/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3866\n",
      "Epoch 249/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3871\n",
      "Epoch 250/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3870\n",
      "Epoch 251/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3864\n",
      "Epoch 252/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 253/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 254/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3864\n",
      "Epoch 255/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3871\n",
      "Epoch 256/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3864\n",
      "Epoch 257/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 258/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3871\n",
      "Epoch 259/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 260/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 261/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 262/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 263/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 264/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 265/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 266/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 267/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 268/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 269/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 270/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 271/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 272/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 273/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 274/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 275/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 276/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 277/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 278/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 279/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 280/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 281/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 282/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3864\n",
      "Epoch 283/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3869\n",
      "Epoch 284/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3871\n",
      "Epoch 285/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 286/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3867\n",
      "Epoch 287/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 288/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3870\n",
      "Epoch 289/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 290/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3864\n",
      "Epoch 291/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 292/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3870\n",
      "Epoch 293/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 294/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3870\n",
      "Epoch 295/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 296/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3870\n",
      "Epoch 297/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 298/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 299/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3861\n",
      "Epoch 300/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 301/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 302/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 303/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 304/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 305/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 306/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 307/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3870\n",
      "Epoch 308/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 309/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3861\n",
      "Epoch 310/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3870\n",
      "Epoch 311/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 312/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 313/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 314/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 315/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3861\n",
      "Epoch 316/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 318/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 319/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3869\n",
      "Epoch 320/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 321/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3861\n",
      "Epoch 322/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3864\n",
      "Epoch 323/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3869\n",
      "Epoch 324/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 325/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3861\n",
      "Epoch 326/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3870\n",
      "Epoch 327/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3869\n",
      "Epoch 328/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 329/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 330/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3869\n",
      "Epoch 331/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3863\n",
      "Epoch 332/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 333/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 334/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3864\n",
      "Epoch 335/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 336/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3862\n",
      "Epoch 337/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3861\n",
      "Epoch 338/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3869\n",
      "Epoch 339/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3869\n",
      "Epoch 340/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 341/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3861\n",
      "Epoch 342/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3863\n",
      "Epoch 343/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3869\n",
      "Epoch 344/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 345/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3861\n",
      "Epoch 346/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3870\n",
      "Epoch 347/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3869\n",
      "Epoch 348/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3861\n",
      "Epoch 349/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3862\n",
      "Epoch 350/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3869\n",
      "Epoch 351/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3864\n",
      "Epoch 352/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5645 - val_loss: -1.3897\n",
      "Epoch 353/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5713 - val_loss: -1.3886\n",
      "Epoch 354/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5644 - val_loss: -1.3883\n",
      "Epoch 355/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5714 - val_loss: -1.3891\n",
      "Epoch 356/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5644 - val_loss: -1.3878\n",
      "Epoch 357/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5712 - val_loss: -1.3875\n",
      "Epoch 358/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5604 - val_loss: -1.3916\n",
      "Epoch 359/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5714 - val_loss: -1.3896\n",
      "Epoch 360/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5640 - val_loss: -1.3939\n",
      "Epoch 361/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5722 - val_loss: -1.3927\n",
      "Epoch 362/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5653 - val_loss: -1.3911\n",
      "Epoch 363/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3896\n",
      "Epoch 364/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3886\n",
      "Epoch 365/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3889\n",
      "Epoch 366/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3888\n",
      "Epoch 367/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3879\n",
      "Epoch 368/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3885\n",
      "Epoch 369/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3888\n",
      "Epoch 370/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3886\n",
      "Epoch 371/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3889\n",
      "Epoch 372/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3892\n",
      "Epoch 373/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3878\n",
      "Epoch 374/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3887\n",
      "Epoch 375/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3891\n",
      "Epoch 376/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3884\n",
      "Epoch 377/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3887\n",
      "Epoch 378/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3886\n",
      "Epoch 379/500\n",
      "35/35 [==============================] - 1s 17ms/step - loss: -1.5723 - val_loss: -1.3891\n",
      "Epoch 380/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3892\n",
      "Epoch 381/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3887\n",
      "Epoch 382/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3885\n",
      "Epoch 383/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3891\n",
      "Epoch 384/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3891\n",
      "Epoch 385/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3878\n",
      "Epoch 386/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3886\n",
      "Epoch 387/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3890\n",
      "Epoch 388/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3884\n",
      "Epoch 389/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3887\n",
      "Epoch 390/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3885\n",
      "Epoch 391/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3891\n",
      "Epoch 392/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3891\n",
      "Epoch 393/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3887\n",
      "Epoch 394/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5654 - val_loss: -1.3886\n",
      "Epoch 395/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3891\n",
      "Epoch 397/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3881\n",
      "Epoch 398/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3886\n",
      "Epoch 399/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3890\n",
      "Epoch 400/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3884\n",
      "Epoch 401/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3887\n",
      "Epoch 402/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3885\n",
      "Epoch 403/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5723 - val_loss: -1.3890\n",
      "Epoch 404/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3891\n",
      "Epoch 405/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3881\n",
      "Epoch 406/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3886\n",
      "Epoch 407/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3883\n",
      "Epoch 408/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3882\n",
      "Epoch 409/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3887\n",
      "Epoch 410/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5654 - val_loss: -1.3885\n",
      "Epoch 411/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5711 - val_loss: -1.3943\n",
      "Epoch 412/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5651 - val_loss: -1.3904\n",
      "Epoch 413/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5722 - val_loss: -1.3900\n",
      "Epoch 414/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5653 - val_loss: -1.3906\n",
      "Epoch 415/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5722 - val_loss: -1.3909\n",
      "Epoch 416/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5653 - val_loss: -1.3890\n",
      "Epoch 417/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5722 - val_loss: -1.3890\n",
      "Epoch 418/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5653 - val_loss: -1.3890\n",
      "Epoch 419/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5722 - val_loss: -1.3890\n",
      "Epoch 420/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5653 - val_loss: -1.3893\n",
      "Epoch 421/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5722 - val_loss: -1.3894\n",
      "Epoch 422/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5623 - val_loss: -1.3847\n",
      "Epoch 423/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5723 - val_loss: -1.3914\n",
      "Epoch 424/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5664 - val_loss: -1.3930\n",
      "Epoch 425/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5736 - val_loss: -1.3902\n",
      "Epoch 426/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5666 - val_loss: -1.3888\n",
      "Epoch 427/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5739 - val_loss: -1.3900\n",
      "Epoch 428/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3904\n",
      "Epoch 429/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3901\n",
      "Epoch 430/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3899\n",
      "Epoch 431/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3904\n",
      "Epoch 432/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3894\n",
      "Epoch 433/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3894\n",
      "Epoch 434/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3889\n",
      "Epoch 435/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3883\n",
      "Epoch 436/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3876\n",
      "Epoch 437/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3888\n",
      "Epoch 438/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3891\n",
      "Epoch 439/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3877\n",
      "Epoch 440/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3878\n",
      "Epoch 441/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3878\n",
      "Epoch 442/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3886\n",
      "Epoch 443/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3884\n",
      "Epoch 444/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5670 - val_loss: -1.3877\n",
      "Epoch 445/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5740 - val_loss: -1.3873\n",
      "Epoch 446/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3880\n",
      "Epoch 447/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3888\n",
      "Epoch 448/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5670 - val_loss: -1.3885\n",
      "Epoch 449/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3885\n",
      "Epoch 450/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3890\n",
      "Epoch 451/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3871\n",
      "Epoch 452/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3876\n",
      "Epoch 453/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3877\n",
      "Epoch 454/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3882\n",
      "Epoch 455/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3877\n",
      "Epoch 456/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3884\n",
      "Epoch 457/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3886\n",
      "Epoch 458/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3890\n",
      "Epoch 459/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3885\n",
      "Epoch 460/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3886\n",
      "Epoch 461/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3871\n",
      "Epoch 462/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5670 - val_loss: -1.3877\n",
      "Epoch 463/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3872\n",
      "Epoch 464/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5670 - val_loss: -1.3877\n",
      "Epoch 465/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3886\n",
      "Epoch 466/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3885\n",
      "Epoch 467/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3886\n",
      "Epoch 468/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3890\n",
      "Epoch 469/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3883\n",
      "Epoch 470/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3893\n",
      "Epoch 471/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3887\n",
      "Epoch 472/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3883\n",
      "Epoch 473/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3871\n",
      "Epoch 474/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5670 - val_loss: -1.3877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3876\n",
      "Epoch 476/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3886\n",
      "Epoch 477/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5740 - val_loss: -1.3881\n",
      "Epoch 478/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3887\n",
      "Epoch 479/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3889\n",
      "Epoch 480/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3885\n",
      "Epoch 481/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3886\n",
      "Epoch 482/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3885\n",
      "Epoch 483/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3887\n",
      "Epoch 484/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3885\n",
      "Epoch 485/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3886\n",
      "Epoch 486/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3885\n",
      "Epoch 487/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3887\n",
      "Epoch 488/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3885\n",
      "Epoch 489/500\n",
      "35/35 [==============================] - 1s 16ms/step - loss: -1.5740 - val_loss: -1.3886\n",
      "Epoch 490/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3885\n",
      "Epoch 491/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3886\n",
      "Epoch 492/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3882\n",
      "Epoch 493/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3879\n",
      "Epoch 494/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3889\n",
      "Epoch 495/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3885\n",
      "Epoch 496/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3882\n",
      "Epoch 497/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3881\n",
      "Epoch 498/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3894\n",
      "Epoch 499/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5740 - val_loss: -1.3882\n",
      "Epoch 500/500\n",
      "35/35 [==============================] - 1s 15ms/step - loss: -1.5670 - val_loss: -1.3881\n"
     ]
    }
   ],
   "source": [
    "model_version = '2.0.0.0.7_encoder_tanhlast_-0.2..0.8_bce_adadelta_ridiculouslysmall'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights' + model_version)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "encoder.fit_generator(fixed_generator(x_train, y_train, batch_size),\n",
    "                steps_per_epoch=x_train.shape[0],\n",
    "                epochs=500,\n",
    "                validation_data=fixed_generator(x_validation, y_validation, batch_size),\n",
    "                validation_steps=x_validation.shape[0]#,\n",
    "#                 callbacks=[checkpointer]\n",
    "                )\n",
    "encoder.save(base_dir + '/ae' + model_version + '.h5')\n",
    "\n",
    "# import keras.losses\n",
    "# keras.losses.MSLE_plus_plus = MSLE_plus_plus\n",
    "# encoder = load_model(base_dir + '/ae' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-255., -255., -255., -255., -255., -255., -255., -255.,  255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255.,  255., -255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255.,  255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255., -255.,  255., -255., -255., -255.,\n",
       "         255., -255., -255., -255., -255., -255., -255., -255.,  255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255.,  255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255., -255., -255., -255., -255., -255., -255.,\n",
       "        -255., -255., -255.]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(encoder.predict(imageio.imread(train_data_dir + \"/class0/patch000001.bmp\").reshape(1,31,31,1))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 46.,  23.,  14.,  11.,  20.,  15.,   8.,  20.,  80.,  46.,  20.,\n",
       "         10.,  14.,  13.,  13.,  29.,  61.,  33.,  20.,  19.,  29.,  22.,\n",
       "         19.,  27.,  20.,  20.,  11.,  24.,  40.,  22.,  25.,  18.,  42.,\n",
       "         17.,  16.,  18.,  25.,  20.,  14.,  23.,  97.,  42.,  23.,  15.,\n",
       "         19.,  16.,  14.,  33.,  85.,  43.,  17.,  22.,  36.,  28.,  27.,\n",
       "         35.,  28.,  22.,  15.,  36.,  47.,  25.,  23.,  24.,  37.,  18.,\n",
       "         11.,  12.,  27.,  35.,  28.,  30.,  90.,  28.,  14.,  15.,  23.,\n",
       "         28.,  23.,  39.,  84.,  43.,  24.,  31.,  37.,  20.,  10.,  28.,\n",
       "         27.,  23.,  27.,  37.,  42.,  20.,  12.,  21.,  28.,  11.,  13.,\n",
       "         15.,  28.,  25.,  21.,  30.,  63.,  21.,  17.,  20.,  23.,  21.,\n",
       "         18.,  42.,  50.,  23.,  19.,  28.,  33.,  19.,  16.,  35.,  25.,\n",
       "         23.,  18.,  20.,  37.,  17.,  10.,  18., 147.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(encoder.predict(imageio.imread(train_data_dir + \"/class0/patch000001.bmp\").reshape(1,31,31,1))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6226.,  -4327.,   -212.,  -5056.,  -7646.,  -6081.,   8609.,\n",
       "          7355.,   5532.,   6354.,   5112.,   1746.,    469.,   4434.,\n",
       "          5450.,   1333.,   5431.,  10231.,   6492.,     11.,   3948.,\n",
       "          3639.,  -1945.,  -1682.,   -183.,  -2503.,   -992.,   -431.,\n",
       "          4361.,   8124.,   2575.,  -1841.,   3022.,    -79.,   1061.,\n",
       "         -3145.,   2384.,   -716.,   8723.,   2711.,   7590.,  -2574.,\n",
       "          2260.,   -314.,   -263.,    203.,    861.,  -2148.,   4120.,\n",
       "          1577.,   1211.,  -3280.,   2762.,   7455.,   6437.,   1561.,\n",
       "           170.,  -4488.,   -589.,    465.,   2837.,   2627.,   3180.,\n",
       "           319.,   1134.,   -845.,  -1492.,  -2196.,  -1676.,  12213.,\n",
       "          -201.,   5783.,   7160.,   1915.,    378.,   4552.,   4211.,\n",
       "           557.,   4883.,   4785.,   4315.,  -4458., -12434.,  -8737.,\n",
       "          5939.,   8673.,   -182.,   -775.,   3257.,  -3857.,  -2258.,\n",
       "         -3089.,  -1088.,  -2382.,  -1468.,   2597.,  -1078.,  -1202.,\n",
       "         -1594.,  -1812.,  -6222.,    321.,   4123.,   7849.,   5432.,\n",
       "           632.,   3401.,   6550.,  -4180.,   7895.,   3273.,   4679.,\n",
       "          6465.,  10767.,  -2702.,  -5345.,   7447.,   2862.,   1713.,\n",
       "          5120.,  -7314.,   -679.,  -6101.,   1573.,   4818.,   3201.,\n",
       "          1188.,  -1828.,  11770.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(encoder.predict(imageio.imread(train_data_dir + \"/class0/patch000003.bmp\").reshape(1,31,31,1))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 46.,  23.,  14.,  11.,  20.,  15.,   8.,  20.,  80.,  46.,  20.,\n",
       "         10.,  14.,  13.,  13.,  29.,  61.,  33.,  20.,  19.,  29.,  22.,\n",
       "         19.,  27.,  20.,  20.,  11.,  24.,  40.,  22.,  25.,  18.,  42.,\n",
       "         17.,  16.,  18.,  25.,  20.,  14.,  23.,  97.,  42.,  23.,  15.,\n",
       "         19.,  16.,  14.,  33.,  85.,  43.,  17.,  22.,  36.,  28.,  27.,\n",
       "         35.,  28.,  22.,  15.,  36.,  47.,  25.,  23.,  24.,  37.,  18.,\n",
       "         11.,  12.,  27.,  35.,  28.,  30.,  90.,  28.,  14.,  15.,  23.,\n",
       "         28.,  23.,  39.,  84.,  43.,  24.,  31.,  37.,  20.,  10.,  28.,\n",
       "         27.,  23.,  27.,  37.,  42.,  20.,  12.,  21.,  28.,  11.,  13.,\n",
       "         15.,  28.,  25.,  21.,  30.,  63.,  21.,  17.,  20.,  23.,  21.,\n",
       "         18.,  42.,  50.,  23.,  19.,  28.,  33.,  19.,  16.,  35.,  25.,\n",
       "         23.,  18.,  20.,  37.,  17.,  10.,  18., 147.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(encoder.predict(imageio.imread(train_data_dir + \"/class0/patch000001.bmp\").reshape(1,31,31,1))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   1,   0,   0, 137,  42,   1,   3,  55,   7,   0,   0,  71,\n",
       "        32,   1,   3, 137,  39,   0,   0,   3,   2,   0,   5,  40,  10,\n",
       "         1,  13,  81,   1,   0,   1,  11,   2,   0,   0, 137,  64,   1,\n",
       "         1,  54,   2,   0,   0, 109,  23,   1,   4, 137,  33,   4,   2,\n",
       "         8,   2,   0,   8,  40,  16,  12,  83,  83,   0,   0,   1,  27,\n",
       "         9,   0,   1, 137,  58,   2,   0,  23,   0,   0,   0,  54,  62,\n",
       "        17,  18, 137,  36,  12,   8,   5,  10,   9,  34,  10,  16,  22,\n",
       "       137,  76,   2,   0,   0,  50,   8,   0,   1, 137,  57,   1,   1,\n",
       "        26,   1,   0,   0,  31,  26,  18,  19,  19,   2,   4,   4,  10,\n",
       "        10,  17,  47,   1,   1,   2,  27, 137,  25,   2,   3,  19],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(train_descrs_dir + \"/class0/descr_angle_000001.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01960784, 0.03137255, 0.03137255, 0.01176471, 0.05490196,\n",
       "       0.02745098, 0.09411765, 0.18039216, 0.03137255, 0.05490196,\n",
       "       0.10196078, 0.02352941, 0.05490196, 0.20392157, 0.2745098 ,\n",
       "       0.13333333, 0.00784314, 0.00392157, 0.03137255, 0.05490196,\n",
       "       0.36470588, 0.49019608, 0.09019608, 0.04705882, 0.02745098,\n",
       "       0.00392157, 0.00392157, 0.00392157, 0.03529412, 0.09411765,\n",
       "       0.08235294, 0.17647059, 0.01176471, 0.17254902, 0.49019608,\n",
       "       0.05882353, 0.00392157, 0.        , 0.00392157, 0.01960784,\n",
       "       0.06666667, 0.1254902 , 0.49019608, 0.21176471, 0.02745098,\n",
       "       0.01176471, 0.00392157, 0.01568627, 0.23529412, 0.0745098 ,\n",
       "       0.25098039, 0.11764706, 0.18823529, 0.09411765, 0.23529412,\n",
       "       0.28627451, 0.01176471, 0.        , 0.        , 0.        ,\n",
       "       0.03137255, 0.30196078, 0.49019608, 0.18823529, 0.        ,\n",
       "       0.09803922, 0.45098039, 0.10980392, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.2627451 , 0.22745098, 0.38039216,\n",
       "       0.19215686, 0.        , 0.        , 0.        , 0.00784314,\n",
       "       0.49019608, 0.49019608, 0.14509804, 0.        , 0.        ,\n",
       "       0.        , 0.05098039, 0.19607843, 0.06666667, 0.34509804,\n",
       "       0.16862745, 0.01568627, 0.08235294, 0.17647059, 0.22352941,\n",
       "       0.07843137, 0.        , 0.00784314, 0.16470588, 0.0745098 ,\n",
       "       0.01568627, 0.        , 0.        , 0.        , 0.03529412,\n",
       "       0.21176471, 0.12156863, 0.10196078, 0.00392157, 0.        ,\n",
       "       0.        , 0.        , 0.18039216, 0.49019608, 0.25882353,\n",
       "       0.00392157, 0.        , 0.        , 0.        , 0.01568627,\n",
       "       0.30588235, 0.49019608, 0.18823529, 0.01568627, 0.04313725,\n",
       "       0.01176471, 0.00392157, 0.10980392, 0.63529412])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_test16/class0/patch000026.png\").reshape(1,16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y_prime = encoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_train16/class0/patch000012.png\").reshape(1,16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y = np.load(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_sifts/tiny_train16/class0/patch000012.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6393183138370047 \n",
      "\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "   91.000000    1.000000\n",
      "   18.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    1.000000    0.000000\n",
      "    7.000000    1.000000\n",
      "   56.000000    0.000000\n",
      "  157.000000    0.000000\n",
      "  157.000000    1.000000\n",
      "  103.000000    1.000000\n",
      "   21.000000    0.000000\n",
      "    2.000000    1.000000\n",
      "    3.000000    0.000000\n",
      "   16.000000    1.000000\n",
      "   96.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "  110.000000    1.000000\n",
      "   14.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    3.000000    0.000000\n",
      "    9.000000    0.984089\n",
      "   33.000000    0.000000\n",
      "  157.000000    0.000000\n",
      "  157.000000    1.000000\n",
      "  125.000000    1.000000\n",
      "   15.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    9.000000    0.000000\n",
      "   25.000000    1.000000\n",
      "   48.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(temp_y, temp_y_prime[0])[1,0], \"\\n\")\n",
    "for i in range(temp_y_prime.shape[1]):\n",
    "    print('{:>12f}{:>12f}'.format(temp_y[i], temp_y_prime[0, i]))      \n",
    "#     print(temp_y_prime[0, i], temp_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 3.427e-06, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(temp, decimals=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0122 20:00:43.071549 140376228677440 deprecation.py:323] From /scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
