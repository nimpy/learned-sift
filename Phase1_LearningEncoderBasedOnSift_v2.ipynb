{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D, Conv2D, Flatten, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras import backend as K\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import system\n",
    "import os\n",
    "import random\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 31, 31\n",
    "\n",
    "nb_epoch = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/scratch/image_datasets/1_for_learned_sift/ready'\n",
    "\n",
    "train_data_dir      = base_dir + '/patches/train'\n",
    "validation_data_dir = base_dir + '/patches/validation'\n",
    "test_data_dir       = base_dir + '/patches/test'\n",
    "\n",
    "train_descrs_dir      = base_dir + '/descriptors_angles/train'\n",
    "validation_descrs_dir = base_dir + '/descriptors_angles/validation'\n",
    "test_descrs_dir       = base_dir + '/descriptors_angles/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_data(dir_patches, dir_descrs):\n",
    "    files_patches = listdir(dir_patches + '/class0')\n",
    "    files_patches.sort()\n",
    "    \n",
    "    files_descrs = listdir(dir_descrs + '/class0')\n",
    "    files_descrs.sort()\n",
    "    \n",
    "    assert len(files_patches) == len(files_descrs), \"The number of patches doesn't match the number of descriptors.\"\n",
    "\n",
    "    patches = []\n",
    "    descrs = []\n",
    "\n",
    "    \n",
    "    for file_patch, file_descr in zip(files_patches, files_descrs):\n",
    "        patch = imageio.imread(dir_patches + '/class0/' + file_patch)\n",
    "#         print(patch.shape)\n",
    "        if patch.shape[0] == 31:\n",
    "            patches.append(patch)\n",
    "            descr = np.load(dir_descrs + '/class0/' + file_descr)\n",
    "            descrs.append(descr)\n",
    "#         elif image.shape[0] == 19:\n",
    "#             temp_count19 += 1\n",
    "        \n",
    "        \n",
    "\n",
    "    patches = np.array(patches)\n",
    "    patches = patches.astype(np.float64) / 255\n",
    "    \n",
    "    descrs = np.array(descrs)\n",
    "    descrs = descrs.astype(np.float64) / 255\n",
    "    print(\"patches\", patches.shape, \"  descrs\", descrs.shape)\n",
    "    \n",
    "    return patches, descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patches (3382, 31, 31)   descrs (3382, 129)\n",
      "patches (409, 31, 31)   descrs (409, 129)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = loading_data(train_data_dir, train_descrs_dir)\n",
    "x_validation, y_validation = loading_data(validation_data_dir, validation_descrs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[2], x_train.shape[2], 1))\n",
    "x_validation = x_validation.reshape((x_validation.shape[0], x_validation.shape[2], x_validation.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 31, 31, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSLE_plus_plus(y_true, y_pred):\n",
    "    if not K.is_tensor(y_pred):\n",
    "        y_pred = K.constant(y_pred)\n",
    "    y_true = K.cast(y_true, y_pred.dtype)\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    custom_loss_log = K.log(K.clip(y_true + y_pred, K.epsilon(), None) + 1.)\n",
    "    custom_loss_denominator = (y_true * y_pred + 0.005) * 256  # parameters to be further adjusted\n",
    "    return K.mean(K.square(first_log - second_log) + custom_loss_log / custom_loss_denominator, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 31, 31, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 23, 23, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 21, 21, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 129)               51729     \n",
      "=================================================================\n",
      "Total params: 84,417\n",
      "Trainable params: 84,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (img_width, img_height, 1)\n",
    "input_img = Input(shape=input_shape)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(input_img)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = Conv2D(16, (3, 3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = MaxPooling2D((4, 4), padding=\"valid\")(x)\n",
    "x = Flatten(data_format=\"channels_last\")(x)\n",
    "encoded = Dense(129, activation=\"sigmoid\")(x)\n",
    "\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "encoder.compile(optimizer='adadelta', loss=\"binary_crossentropy\")\n",
    "#next up: encoder.compile(optimizer='sgd', metrics=['categorical_accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_generator(x_train, y_train, batch_size):\n",
    "    while True:\n",
    "        batch_list_x = []\n",
    "        batch_list_y = []\n",
    "        \n",
    "        for i in range(x_train.shape[0]):\n",
    "            batch_list_x.append(x_train[i])\n",
    "            batch_list_y.append(y_train[i])\n",
    "            if len(batch_list_x) == batch_size:\n",
    "                yield (np.array(batch_list_x),np.array(batch_list_y))\n",
    "                batch_list_x = []\n",
    "                batch_list_y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = '2.0.0.0_encoder_lastsigmoid_bce_adadelta'\n",
    "encoder = load_model(base_dir + '/ae' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2930 - val_loss: 0.3791\n",
      "Epoch 2/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2930 - val_loss: 0.3732\n",
      "Epoch 3/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2929 - val_loss: 0.4069\n",
      "Epoch 4/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2930 - val_loss: 0.3920\n",
      "Epoch 5/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2929 - val_loss: 0.3940\n",
      "Epoch 6/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2929 - val_loss: 0.3600\n",
      "Epoch 7/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2928 - val_loss: 0.3750\n",
      "Epoch 8/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2927 - val_loss: 0.4113\n",
      "Epoch 9/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2929 - val_loss: 0.3574\n",
      "Epoch 10/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2927 - val_loss: 0.4153\n",
      "Epoch 11/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2927 - val_loss: 0.4234\n",
      "Epoch 12/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2926 - val_loss: 0.3902\n",
      "Epoch 13/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2926 - val_loss: 0.3815\n",
      "Epoch 14/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2927 - val_loss: 0.3776\n",
      "Epoch 15/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2926 - val_loss: 0.4080\n",
      "Epoch 16/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2925 - val_loss: 0.3937\n",
      "Epoch 17/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2924 - val_loss: 0.4097\n",
      "Epoch 18/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2925 - val_loss: 0.3650\n",
      "Epoch 19/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2926 - val_loss: 0.3736\n",
      "Epoch 20/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2924 - val_loss: 0.4095\n",
      "Epoch 21/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2925 - val_loss: 0.3578\n",
      "Epoch 22/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2923 - val_loss: 0.4191\n",
      "Epoch 23/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2924 - val_loss: 0.4271\n",
      "Epoch 24/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2924 - val_loss: 0.3890\n",
      "Epoch 25/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2923 - val_loss: 0.3813\n",
      "Epoch 26/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2923 - val_loss: 0.3758\n",
      "Epoch 27/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2922 - val_loss: 0.4114\n",
      "Epoch 28/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2923 - val_loss: 0.3916\n",
      "Epoch 29/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2922 - val_loss: 0.3975\n",
      "Epoch 30/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2922 - val_loss: 0.3701\n",
      "Epoch 31/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2922 - val_loss: 0.3776\n",
      "Epoch 32/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2922 - val_loss: 0.4159\n",
      "Epoch 33/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2922 - val_loss: 0.3573\n",
      "Epoch 34/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2921 - val_loss: 0.4200\n",
      "Epoch 35/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2921 - val_loss: 0.4300\n",
      "Epoch 36/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2920 - val_loss: 0.3903\n",
      "Epoch 37/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2920 - val_loss: 0.3909\n",
      "Epoch 38/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2921 - val_loss: 0.3743\n",
      "Epoch 39/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2920 - val_loss: 0.4128\n",
      "Epoch 40/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2920 - val_loss: 0.3980\n",
      "Epoch 41/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2919 - val_loss: 0.4159\n",
      "Epoch 42/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2920 - val_loss: 0.3732\n",
      "Epoch 43/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2920 - val_loss: 0.3742\n",
      "Epoch 44/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2919 - val_loss: 0.4131\n",
      "Epoch 45/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2919 - val_loss: 0.3567\n",
      "Epoch 46/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2918 - val_loss: 0.4265\n",
      "Epoch 47/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2919 - val_loss: 0.4239\n",
      "Epoch 48/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2919 - val_loss: 0.3942\n",
      "Epoch 49/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2918 - val_loss: 0.3820\n",
      "Epoch 50/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2918 - val_loss: 0.3807\n",
      "Epoch 51/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2918 - val_loss: 0.4148\n",
      "Epoch 52/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2918 - val_loss: 0.4007\n",
      "Epoch 53/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2918 - val_loss: 0.4029\n",
      "Epoch 54/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2917 - val_loss: 0.3689\n",
      "Epoch 55/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2917 - val_loss: 0.3786\n",
      "Epoch 56/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2917 - val_loss: 0.4224\n",
      "Epoch 57/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2918 - val_loss: 0.3591\n",
      "Epoch 58/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2917 - val_loss: 0.4212\n",
      "Epoch 59/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2917 - val_loss: 0.4392\n",
      "Epoch 60/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2916 - val_loss: 0.3966\n",
      "Epoch 61/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2917 - val_loss: 0.3906\n",
      "Epoch 62/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2917 - val_loss: 0.3799\n",
      "Epoch 63/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2916 - val_loss: 0.4180\n",
      "Epoch 64/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2916 - val_loss: 0.3992\n",
      "Epoch 65/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.4150\n",
      "Epoch 66/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2916 - val_loss: 0.3654\n",
      "Epoch 67/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2916 - val_loss: 0.3744\n",
      "Epoch 68/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.4121\n",
      "Epoch 69/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.3588\n",
      "Epoch 70/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.4292\n",
      "Epoch 71/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2916 - val_loss: 0.4354\n",
      "Epoch 72/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.3923\n",
      "Epoch 73/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.3843\n",
      "Epoch 74/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2914 - val_loss: 0.3833\n",
      "Epoch 75/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.4199\n",
      "Epoch 76/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.4044\n",
      "Epoch 77/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2915 - val_loss: 0.4067\n",
      "Epoch 78/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2914 - val_loss: 0.3674\n",
      "Epoch 79/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2913 - val_loss: 0.3812\n",
      "Epoch 80/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2914 - val_loss: 0.4215\n",
      "Epoch 81/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2915 - val_loss: 0.3615\n",
      "Epoch 82/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2914 - val_loss: 0.4210\n",
      "Epoch 83/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2914 - val_loss: 0.4412\n",
      "Epoch 84/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2913 - val_loss: 0.3944\n",
      "Epoch 85/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2914 - val_loss: 0.3940\n",
      "Epoch 86/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2914 - val_loss: 0.3834\n",
      "Epoch 87/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2913 - val_loss: 0.4188\n",
      "Epoch 88/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2913 - val_loss: 0.4034\n",
      "Epoch 89/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.4182\n",
      "Epoch 90/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2914 - val_loss: 0.3691\n",
      "Epoch 91/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2913 - val_loss: 0.3818\n",
      "Epoch 92/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.4217\n",
      "Epoch 93/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.3607\n",
      "Epoch 94/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.4274\n",
      "Epoch 95/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2913 - val_loss: 0.4413\n",
      "Epoch 96/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.3929\n",
      "Epoch 97/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.3877\n",
      "Epoch 98/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.3935\n",
      "Epoch 99/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.4150\n",
      "Epoch 100/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2913 - val_loss: 0.4055\n",
      "Epoch 101/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2911 - val_loss: 0.4112\n",
      "Epoch 102/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2912 - val_loss: 0.3719\n",
      "Epoch 103/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2911 - val_loss: 0.3815\n",
      "Epoch 104/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.4220\n",
      "Epoch 105/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.3596\n",
      "Epoch 106/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2911 - val_loss: 0.4226\n",
      "Epoch 107/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2911 - val_loss: 0.4521\n",
      "Epoch 108/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2911 - val_loss: 0.3976\n",
      "Epoch 109/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.3939\n",
      "Epoch 110/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2911 - val_loss: 0.3913\n",
      "Epoch 111/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2911 - val_loss: 0.4213\n",
      "Epoch 112/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2911 - val_loss: 0.4056\n",
      "Epoch 113/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2910 - val_loss: 0.4179\n",
      "Epoch 114/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2912 - val_loss: 0.3717\n",
      "Epoch 115/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2911 - val_loss: 0.3874\n",
      "Epoch 116/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2910 - val_loss: 0.4253\n",
      "Epoch 117/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2910 - val_loss: 0.3623\n",
      "Epoch 118/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2910 - val_loss: 0.4305\n",
      "Epoch 119/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2911 - val_loss: 0.4502\n",
      "Epoch 120/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2910 - val_loss: 0.3935\n",
      "Epoch 121/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2910 - val_loss: 0.3932\n",
      "Epoch 122/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2909 - val_loss: 0.3900\n",
      "Epoch 123/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2910 - val_loss: 0.4215\n",
      "Epoch 124/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2910 - val_loss: 0.4107\n",
      "Epoch 125/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2909 - val_loss: 0.4090\n",
      "Epoch 126/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2910 - val_loss: 0.3715\n",
      "Epoch 127/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.3881\n",
      "Epoch 128/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2910 - val_loss: 0.4196\n",
      "Epoch 129/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2909 - val_loss: 0.3615\n",
      "Epoch 130/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2909 - val_loss: 0.4222\n",
      "Epoch 131/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2909 - val_loss: 0.4583\n",
      "Epoch 132/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4026\n",
      "Epoch 133/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2909 - val_loss: 0.3998\n",
      "Epoch 134/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2909 - val_loss: 0.3903\n",
      "Epoch 135/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4300\n",
      "Epoch 136/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4061\n",
      "Epoch 137/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4131\n",
      "Epoch 138/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2909 - val_loss: 0.3736\n",
      "Epoch 139/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2908 - val_loss: 0.3898\n",
      "Epoch 140/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4319\n",
      "Epoch 141/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2907 - val_loss: 0.3589\n",
      "Epoch 142/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4267\n",
      "Epoch 143/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2909 - val_loss: 0.4516\n",
      "Epoch 144/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2907 - val_loss: 0.3950\n",
      "Epoch 145/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4005\n",
      "Epoch 146/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2907 - val_loss: 0.3837\n",
      "Epoch 147/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4190\n",
      "Epoch 148/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2907 - val_loss: 0.4126\n",
      "Epoch 149/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2907 - val_loss: 0.4113\n",
      "Epoch 150/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2907 - val_loss: 0.3751\n",
      "Epoch 151/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2906 - val_loss: 0.3912\n",
      "Epoch 152/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2908 - val_loss: 0.4231\n",
      "Epoch 153/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2907 - val_loss: 0.3593\n",
      "Epoch 154/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2906 - val_loss: 0.4231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2907 - val_loss: 0.4581\n",
      "Epoch 156/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2906 - val_loss: 0.4080\n",
      "Epoch 157/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2907 - val_loss: 0.4029\n",
      "Epoch 158/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.3900\n",
      "Epoch 159/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.4286\n",
      "Epoch 160/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.4117\n",
      "Epoch 161/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.4183\n",
      "Epoch 162/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2907 - val_loss: 0.3722\n",
      "Epoch 163/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.3950\n",
      "Epoch 164/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.4344\n",
      "Epoch 165/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.3599\n",
      "Epoch 166/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.4303\n",
      "Epoch 167/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.4504\n",
      "Epoch 168/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.3915\n",
      "Epoch 169/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2906 - val_loss: 0.4008\n",
      "Epoch 170/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.3858\n",
      "Epoch 171/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.4263\n",
      "Epoch 172/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.4140\n",
      "Epoch 173/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.4066\n",
      "Epoch 174/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.3817\n",
      "Epoch 175/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.3982\n",
      "Epoch 176/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2906 - val_loss: 0.4250\n",
      "Epoch 177/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.3614\n",
      "Epoch 178/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.4286\n",
      "Epoch 179/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4613\n",
      "Epoch 180/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.4096\n",
      "Epoch 181/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2906 - val_loss: 0.4001\n",
      "Epoch 182/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.3942\n",
      "Epoch 183/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.4359\n",
      "Epoch 184/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4084\n",
      "Epoch 185/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.4130\n",
      "Epoch 186/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.3735\n",
      "Epoch 187/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.3980\n",
      "Epoch 188/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.4320\n",
      "Epoch 189/400\n",
      "3382/3382 [==============================] - 66s 20ms/step - loss: 0.2903 - val_loss: 0.3605\n",
      "Epoch 190/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2905 - val_loss: 0.4317\n",
      "Epoch 191/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.4514\n",
      "Epoch 192/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.3918\n",
      "Epoch 193/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.3996\n",
      "Epoch 194/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.3904\n",
      "Epoch 195/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2905 - val_loss: 0.4311\n",
      "Epoch 196/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4076\n",
      "Epoch 197/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.4142\n",
      "Epoch 198/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.3757\n",
      "Epoch 199/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4018\n",
      "Epoch 200/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4275\n",
      "Epoch 201/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.3612\n",
      "Epoch 202/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4290\n",
      "Epoch 203/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4652\n",
      "Epoch 204/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2903 - val_loss: 0.4075\n",
      "Epoch 205/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.4030\n",
      "Epoch 206/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.3925\n",
      "Epoch 207/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2904 - val_loss: 0.4394\n",
      "Epoch 208/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4138\n",
      "Epoch 209/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4236\n",
      "Epoch 210/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.3763\n",
      "Epoch 211/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4050\n",
      "Epoch 212/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4289\n",
      "Epoch 213/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.3621\n",
      "Epoch 214/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4334\n",
      "Epoch 215/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2903 - val_loss: 0.4585\n",
      "Epoch 216/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.3954\n",
      "Epoch 217/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4023\n",
      "Epoch 218/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2902 - val_loss: 0.3911\n",
      "Epoch 219/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2904 - val_loss: 0.4350\n",
      "Epoch 220/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4072\n",
      "Epoch 221/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4148\n",
      "Epoch 222/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.3757\n",
      "Epoch 223/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4058\n",
      "Epoch 224/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4319\n",
      "Epoch 225/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2903 - val_loss: 0.3610\n",
      "Epoch 226/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2903 - val_loss: 0.4334\n",
      "Epoch 227/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2902 - val_loss: 0.4566\n",
      "Epoch 228/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2902 - val_loss: 0.4145\n",
      "Epoch 229/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2903 - val_loss: 0.4025\n",
      "Epoch 230/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2902 - val_loss: 0.3942\n",
      "Epoch 231/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2903 - val_loss: 0.4389\n",
      "Epoch 232/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4128\n",
      "Epoch 233/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2903 - val_loss: 0.4183\n",
      "Epoch 234/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.3779\n",
      "Epoch 235/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.3933\n",
      "Epoch 236/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4374\n",
      "Epoch 237/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3620\n",
      "Epoch 238/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2903 - val_loss: 0.4326\n",
      "Epoch 239/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4535\n",
      "Epoch 240/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.3995\n",
      "Epoch 241/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4062\n",
      "Epoch 242/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.3921\n",
      "Epoch 243/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2903 - val_loss: 0.4364\n",
      "Epoch 244/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4100\n",
      "Epoch 245/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4169\n",
      "Epoch 246/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3805\n",
      "Epoch 247/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4082\n",
      "Epoch 248/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4347\n",
      "Epoch 249/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3593\n",
      "Epoch 250/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4382\n",
      "Epoch 251/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4582\n",
      "Epoch 252/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4071\n",
      "Epoch 253/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4052\n",
      "Epoch 254/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.3980\n",
      "Epoch 255/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4390\n",
      "Epoch 256/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4151\n",
      "Epoch 257/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4174\n",
      "Epoch 258/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3743\n",
      "Epoch 259/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3966\n",
      "Epoch 260/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4353\n",
      "Epoch 261/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3626\n",
      "Epoch 262/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4346\n",
      "Epoch 263/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4514\n",
      "Epoch 264/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4007\n",
      "Epoch 265/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4079\n",
      "Epoch 266/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3952\n",
      "Epoch 267/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2902 - val_loss: 0.4341\n",
      "Epoch 268/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4133\n",
      "Epoch 269/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4193\n",
      "Epoch 270/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.3791\n",
      "Epoch 271/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4086\n",
      "Epoch 272/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4364\n",
      "Epoch 273/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3599\n",
      "Epoch 274/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4351\n",
      "Epoch 275/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4521\n",
      "Epoch 276/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4044\n",
      "Epoch 277/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4034\n",
      "Epoch 278/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2901 - val_loss: 0.3979\n",
      "Epoch 279/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4404\n",
      "Epoch 280/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4200\n",
      "Epoch 281/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4183\n",
      "Epoch 282/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3751\n",
      "Epoch 283/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.3999\n",
      "Epoch 284/400\n",
      "3382/3382 [==============================] - 66s 20ms/step - loss: 0.2900 - val_loss: 0.4390\n",
      "Epoch 285/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.3648\n",
      "Epoch 286/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2901 - val_loss: 0.4336\n",
      "Epoch 287/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4553\n",
      "Epoch 288/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4072\n",
      "Epoch 289/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4087\n",
      "Epoch 290/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.3943\n",
      "Epoch 291/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2901 - val_loss: 0.4361\n",
      "Epoch 292/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2900 - val_loss: 0.4158\n",
      "Epoch 293/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4161\n",
      "Epoch 294/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.3767\n",
      "Epoch 295/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2901 - val_loss: 0.4050\n",
      "Epoch 296/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2900 - val_loss: 0.4390\n",
      "Epoch 297/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2900 - val_loss: 0.3644\n",
      "Epoch 298/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2900 - val_loss: 0.4402\n",
      "Epoch 299/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4561\n",
      "Epoch 300/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2901 - val_loss: 0.4115\n",
      "Epoch 301/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2900 - val_loss: 0.4001\n",
      "Epoch 302/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4011\n",
      "Epoch 303/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2899 - val_loss: 0.4335\n",
      "Epoch 304/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4199\n",
      "Epoch 305/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4133\n",
      "Epoch 306/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.3783\n",
      "Epoch 307/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.3973\n",
      "Epoch 308/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4394\n",
      "Epoch 309/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.3631\n",
      "Epoch 310/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4440\n",
      "Epoch 311/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4626\n",
      "Epoch 312/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4139\n",
      "Epoch 313/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4046\n",
      "Epoch 314/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.3929\n",
      "Epoch 315/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4333\n",
      "Epoch 316/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4166\n",
      "Epoch 317/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4179\n",
      "Epoch 318/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.3762\n",
      "Epoch 319/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4054\n",
      "Epoch 320/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4389\n",
      "Epoch 321/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.3609\n",
      "Epoch 322/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4401\n",
      "Epoch 323/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4557\n",
      "Epoch 324/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2900 - val_loss: 0.4129\n",
      "Epoch 325/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4015\n",
      "Epoch 326/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4024\n",
      "Epoch 327/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4354\n",
      "Epoch 328/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4205\n",
      "Epoch 329/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4122\n",
      "Epoch 330/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.3791\n",
      "Epoch 331/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2899 - val_loss: 0.3962\n",
      "Epoch 332/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4430\n",
      "Epoch 333/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.3672\n",
      "Epoch 334/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4453\n",
      "Epoch 335/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4612\n",
      "Epoch 336/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2899 - val_loss: 0.4105\n",
      "Epoch 337/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4045\n",
      "Epoch 338/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.3949\n",
      "Epoch 339/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2899 - val_loss: 0.4410\n",
      "Epoch 340/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4136\n",
      "Epoch 341/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4239\n",
      "Epoch 342/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.3798\n",
      "Epoch 343/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4075\n",
      "Epoch 344/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4389\n",
      "Epoch 345/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.3620\n",
      "Epoch 346/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4433\n",
      "Epoch 347/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4644\n",
      "Epoch 348/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2899 - val_loss: 0.4118\n",
      "Epoch 349/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4020\n",
      "Epoch 350/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.4049\n",
      "Epoch 351/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4318\n",
      "Epoch 352/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4228\n",
      "Epoch 353/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2899 - val_loss: 0.4159\n",
      "Epoch 354/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.3844\n",
      "Epoch 355/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.3999\n",
      "Epoch 356/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4385\n",
      "Epoch 357/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.3646\n",
      "Epoch 358/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4458\n",
      "Epoch 359/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.4636\n",
      "Epoch 360/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4111\n",
      "Epoch 361/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4099\n",
      "Epoch 362/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2899 - val_loss: 0.3948\n",
      "Epoch 363/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.4314\n",
      "Epoch 364/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4144\n",
      "Epoch 365/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.4258\n",
      "Epoch 366/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2897 - val_loss: 0.3834\n",
      "Epoch 367/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.3997\n",
      "Epoch 368/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.4440\n",
      "Epoch 369/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.3604\n",
      "Epoch 370/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2897 - val_loss: 0.4424\n",
      "Epoch 371/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4633\n",
      "Epoch 372/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4110\n",
      "Epoch 373/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.3992\n",
      "Epoch 374/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4040\n",
      "Epoch 375/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4283\n",
      "Epoch 376/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4204\n",
      "Epoch 377/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.4212\n",
      "Epoch 378/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.3877\n",
      "Epoch 379/400\n",
      "3382/3382 [==============================] - 68s 20ms/step - loss: 0.2898 - val_loss: 0.4053\n",
      "Epoch 380/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4447\n",
      "Epoch 381/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.3624\n",
      "Epoch 382/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4556\n",
      "Epoch 383/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4543\n",
      "Epoch 384/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4135\n",
      "Epoch 385/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4084\n",
      "Epoch 386/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.3948\n",
      "Epoch 387/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4375\n",
      "Epoch 388/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4164\n",
      "Epoch 389/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4294\n",
      "Epoch 390/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.3855\n",
      "Epoch 391/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4026\n",
      "Epoch 392/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4468\n",
      "Epoch 393/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.3609\n",
      "Epoch 394/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4490\n",
      "Epoch 395/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4535\n",
      "Epoch 396/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4127\n",
      "Epoch 397/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4037\n",
      "Epoch 398/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4046\n",
      "Epoch 399/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2897 - val_loss: 0.4365\n",
      "Epoch 400/400\n",
      "3382/3382 [==============================] - 67s 20ms/step - loss: 0.2898 - val_loss: 0.4165\n"
     ]
    }
   ],
   "source": [
    "model_version = '2.0.0.2_encoder_lastsigmoid_bce_adadelta_moreepochs400'\n",
    "\n",
    "os.system('mkdir ' + base_dir + '/weights' + model_version)\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(base_dir + '/weights' + model_version + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "encoder.fit_generator(fixed_generator(x_train, y_train, 32),\n",
    "                steps_per_epoch=3382,\n",
    "                epochs=400,\n",
    "                validation_data=fixed_generator(x_validation, y_validation, 32),\n",
    "                validation_steps=409,\n",
    "                callbacks=[checkpointer]\n",
    "                )\n",
    "encoder.save(base_dir + '/ae' + model_version + '.h5')\n",
    "\n",
    "# import keras.losses\n",
    "# keras.losses.MSLE_plus_plus = MSLE_plus_plus\n",
    "# encoder = load_model(base_dir + '/ae' + model_version + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255., 255., 255.,   0.,   0.,   0., 255., 255., 255., 255., 195.,\n",
       "          0.,   0.,   0., 255.,   0., 255., 255.,   0., 255.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0., 255., 255., 255.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0., 255., 255., 255., 255.,   0.,   0.,\n",
       "          0.,   0., 255.,   0., 255.,   6.,   0.,   0., 255.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 255., 255.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 255., 255.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0., 255., 255., 255.,   0.,   0.,   0.,   0., 255., 255., 255.,\n",
       "        255.,   0.,   0.,   0., 255., 255., 255., 255.,   0.,   0., 255.,\n",
       "        255.,   0.,   0.,   0.,   0.,   0., 255., 255., 255.,   0.,   0.,\n",
       "          0.,   0., 255., 255., 255.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0., 255.,   0.,   0., 255.,   0., 255.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(encoder.predict(imageio.imread(test_data_dir + \"/class0/patch000013.bmp\").reshape(1,31,31,1))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255., 255., 255., 255.,   0.,   0.,   0.,   0.,   0., 255., 255.,\n",
       "        255., 255.,   0.,   0.,   0., 255., 255.,   0., 255., 255., 255.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0., 255., 255.,   0.,   0.,   0.,\n",
       "         58., 255., 255., 255.,   0.,   0.,   0.,   0., 255., 255., 255.,\n",
       "        255.,   0.,   0.,   0.,   0., 255.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0., 255., 255.,   0.,   0., 255., 255.,\n",
       "        255., 255., 255.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255.,\n",
       "        255., 255., 255.,   0.,   0.,   0.,   0.,   0., 255., 255., 255.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255., 255., 255.,\n",
       "          0.,   0.,   0.,   0., 255.,   0., 255., 255.,   0.,   0., 255.,\n",
       "        255.,   0.,   0.,   0.,   0.,   0.,   0., 255., 255.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0., 194., 255.,   0.,   0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.around(encoder.predict(imageio.imread(train_data_dir + \"/class0/patch000001.bmp\").reshape(1,31,31,1))*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y_prime = encoder.predict(imageio.imread(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_train16/class0/patch000012.png\").reshape(1,16,16,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_y = np.load(\"/home/niaki/Code/ImageNet/tiny-imagenet-200/tiny_sifts/tiny_train16/class0/patch000012.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6393183138370047 \n",
      "\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "   91.000000    1.000000\n",
      "   18.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    1.000000    0.000000\n",
      "    7.000000    1.000000\n",
      "   56.000000    0.000000\n",
      "  157.000000    0.000000\n",
      "  157.000000    1.000000\n",
      "  103.000000    1.000000\n",
      "   21.000000    0.000000\n",
      "    2.000000    1.000000\n",
      "    3.000000    0.000000\n",
      "   16.000000    1.000000\n",
      "   96.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "  110.000000    1.000000\n",
      "   14.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    3.000000    0.000000\n",
      "    9.000000    0.984089\n",
      "   33.000000    0.000000\n",
      "  157.000000    0.000000\n",
      "  157.000000    1.000000\n",
      "  125.000000    1.000000\n",
      "   15.000000    0.000000\n",
      "    1.000000    1.000000\n",
      "    9.000000    0.000000\n",
      "   25.000000    1.000000\n",
      "   48.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "  157.000000    1.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n",
      "    0.000000    0.000000\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(temp_y, temp_y_prime[0])[1,0], \"\\n\")\n",
    "for i in range(temp_y_prime.shape[1]):\n",
    "    print('{:>12f}{:>12f}'.format(temp_y[i], temp_y_prime[0, i]))      \n",
    "#     print(temp_y_prime[0, i], temp_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 3.427e-06, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(temp, decimals=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0122 20:00:43.071549 140376228677440 deprecation.py:323] From /scratch/tensorflow/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
